rank,BAY_AREA_word,BAY_AREA_count,BAY_AREA_z,UK_word,UK_count,UK_z
1,favorite,37,3.2154,london,44,-5.975
2,research,45,2.9434,ideally,26,-3.4873
3,working,76,2.9403,generally,38,-3.4599
4,berkeley,30,2.874,fiction,15,-3.2506
5,lifestyle,43,2.8148,physically,14,-3.0888
6,together,129,2.7621,someone,130,-3.0369
7,partnership,34,2.7552,interest,30,-2.9429
8,relationships,111,2.659,report,12,-2.9071
9,francisco,41,2.5735,exciting,10,-2.8354
10,notion,20,2.3917,respect,14,-2.7493
11,traits,26,2.372,everything,28,-2.6509
12,support,51,2.3082,willing,22,-2.6014
13,emotional,46,2.3044,opinions,11,-2.5356
14,college,18,2.2719,british,8,-2.4902
15,primary,30,2.2611,little,33,-2.4797
16,partners,50,2.2381,things,181,-2.4699
17,feelings,27,2.2347,listening,15,-2.4161
18,anonymous,17,2.2077,travelling,7,-2.38
19,building,42,2.1935,england,7,-2.38
20,toward,16,2.1401,recent,12,-2.3529

In order to calculate the prevalence of bay area style words and uk/london style words in different user groups, we first need to define the word sets for each style based on their distinctiveness in the respective regions. Then, we can analyze the text data from users in the ALL_US, BAY_AREA, and UK_LONDON groups to count occurrences of these words and compute their prevalence per 10,000 words. Finally, we can visualize the results using a bar graph and output the data to a CSV file for further analysis.
We took the most distinctive words from bay area vs non-bay area (from word_graph_04) to define bay area style words, and the most distinctive words from uk/london vs non-uk/london (from word_graph_04) to define uk/london style words. Then we calculated how often these words appear in the text of users from ALL_US, BAY_AREA, and UK_LONDON groups to determine their prevalence per 10,000 words.
We did the same for UK/LONDON style words, using the distinctive words identified from the UK
